# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file

# Allow all search engines to crawl the site
User-agent: *
Allow: /

# Disallow crawling of admin and API routes (if any in the future)
Disallow: /admin/
Disallow: /api/private/

# Sitemap location
Sitemap: https://www.example.com/sitemap.xml
